{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"ONLY_PUBLIC = False","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:42:13.579803Z","iopub.execute_input":"2021-06-17T02:42:13.580174Z","iopub.status.idle":"2021-06-17T02:42:13.587806Z","shell.execute_reply.started":"2021-06-17T02:42:13.580095Z","shell.execute_reply":"2021-06-17T02:42:13.587005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    # !pip install ../input/segmentation-models-wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl -q\n    # !pip install ../input/segmentation-models-wheels/pretrainedmodels-0.7.4-py3-none-any.whl -q\n    !pip install ../input/segmentation-models-wheels/timm-0.3.2-py3-none-any.whl -q\n    # !pip install ../input/segmentationmodelspytorchmaster/segmentation_models.pytorch-master/ -q","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:42:13.948101Z","iopub.execute_input":"2021-06-17T02:42:13.948425Z","iopub.status.idle":"2021-06-17T02:42:40.772381Z","shell.execute_reply.started":"2021-06-17T02:42:13.948394Z","shell.execute_reply":"2021-06-17T02:42:40.771369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    !conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n    !conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n    !conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n    !conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n    !conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n    !conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-17T02:42:40.774161Z","iopub.execute_input":"2021-06-17T02:42:40.774527Z","iopub.status.idle":"2021-06-17T02:43:50.064131Z","shell.execute_reply.started":"2021-06-17T02:42:40.774488Z","shell.execute_reply":"2021-06-17T02:43:50.063189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:    \n    import os\n\n    from PIL import Image\n    import pandas as pd\n    from tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T02:43:50.067957Z","iopub.execute_input":"2021-06-17T02:43:50.068222Z","iopub.status.idle":"2021-06-17T02:43:50.080055Z","shell.execute_reply.started":"2021-06-17T02:43:50.068194Z","shell.execute_reply":"2021-06-17T02:43:50.079303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n    if df.shape[0] == 247: #2477\n        fast_sub = True\n        fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                             ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                             ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                             ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                           columns=['id', 'PredictionString'])\n    else:\n        fast_sub = False\n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:43:50.083022Z","iopub.execute_input":"2021-06-17T02:43:50.083256Z","iopub.status.idle":"2021-06-17T02:43:50.106922Z","shell.execute_reply.started":"2021-06-17T02:43:50.083233Z","shell.execute_reply":"2021-06-17T02:43:50.106203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# .dcm to .png","metadata":{}},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    \n    import numpy as np\n    import pydicom\n    from pydicom.pixel_data_handlers.util import apply_voi_lut\n\n    def read_xray(path, voi_lut = True, fix_monochrome = True):\n        # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n        dicom = pydicom.read_file(path)\n\n        # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n        # \"human-friendly\" view\n        if voi_lut:\n            data = apply_voi_lut(dicom.pixel_array, dicom)\n        else:\n            data = dicom.pixel_array\n\n        # depending on this value, X-ray may look inverted - fix that:\n        if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n            data = np.amax(data) - data\n\n        data = data - np.min(data)\n        data = data / np.max(data)\n        data = (data * 255).astype(np.uint8)\n\n        return data","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:43:50.107981Z","iopub.execute_input":"2021-06-17T02:43:50.108334Z","iopub.status.idle":"2021-06-17T02:43:50.342174Z","shell.execute_reply.started":"2021-06-17T02:43:50.1083Z","shell.execute_reply":"2021-06-17T02:43:50.341359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:    \n    def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n        # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n        im = Image.fromarray(array)\n\n        if keep_ratio:\n            im.thumbnail((size, size), resample)\n        else:\n            im = im.resize((size, size), resample)\n\n        return im","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:43:50.343567Z","iopub.execute_input":"2021-06-17T02:43:50.343902Z","iopub.status.idle":"2021-06-17T02:43:50.351103Z","shell.execute_reply.started":"2021-06-17T02:43:50.343865Z","shell.execute_reply":"2021-06-17T02:43:50.350354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    split = 'test'\n    save_dir = f'/kaggle/tmp/{split}/'\n    os.makedirs(save_dir, exist_ok=True)\n\n    save_dir_image = f'/kaggle/tmp/{split}/image/'\n    os.makedirs(save_dir_image, exist_ok=True)\n\n    save_dir_study = f'/kaggle/tmp/{split}/study/'\n    os.makedirs(save_dir_study, exist_ok=True)\n\n    image_id = []\n    dim0 = []\n    dim1 = []\n    splits = []\n    study_id = []\n\n    if fast_sub:\n        xray = read_xray('../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n        im = resize(xray, size=600)  \n        study = '00086460a852' + '_study.png'\n        im.save(os.path.join(save_dir_study, study))\n        xray = read_xray('../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n        im = resize(xray, size=600)  \n        study = '000c9c05fd14' + '_study.png'\n        im.save(os.path.join(save_dir_study, study))\n        study_id.append('00086460a852')\n        study_id.append('000c9c05fd14')\n    else:   \n        for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n            for file in filenames:\n                # set keep_ratio=True to have original aspect ratio\n                xray = read_xray(os.path.join(dirname, file))\n                im_s = resize(xray, size=600)\n                im_i = resize(xray, size=512)\n                study = dirname.split('/')[-2] + '_study.png'\n                im_s.save(os.path.join(save_dir_study, study))\n                im_i.save(os.path.join(save_dir_image, file.replace('.dcm', '_image.png')))\n                image_id.append(file.replace('.dcm', ''))\n                study_id.append(dirname.split('/')[-2])\n                dim0.append(xray.shape[0])\n                dim1.append(xray.shape[1])\n                splits.append(split)\n            ","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:43:50.352248Z","iopub.execute_input":"2021-06-17T02:43:50.352615Z","iopub.status.idle":"2021-06-17T02:55:15.271097Z","shell.execute_reply.started":"2021-06-17T02:43:50.352578Z","shell.execute_reply":"2021-06-17T02:55:15.270244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    if fast_sub:\n        xray = read_xray('../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n        im = resize(xray, size=512)  \n        im.save(os.path.join(save_dir_image,'65761e66de9f_image.png'))\n        image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n        dim0.append(xray.shape[0])\n        dim1.append(xray.shape[1])\n        splits.append(split)\n        xray = read_xray('../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n        im = resize(xray, size=512)  \n        im.save(os.path.join(save_dir_image, '51759b5579bc_image.png'))\n        image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n        dim0.append(xray.shape[0])\n        dim1.append(xray.shape[1])\n        splits.append(split)\n\n    meta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits, 'study_id': study_id})","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:55:15.274026Z","iopub.execute_input":"2021-06-17T02:55:15.274389Z","iopub.status.idle":"2021-06-17T02:55:15.283965Z","shell.execute_reply.started":"2021-06-17T02:55:15.274356Z","shell.execute_reply":"2021-06-17T02:55:15.283178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# study predict","metadata":{}},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    import numpy as np \n    import pandas as pd\n    if fast_sub:\n        df = fast_df.copy()\n    else:\n        df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n    id_laststr_list  = []\n    for i in range(df.shape[0]):\n        id_laststr_list.append(df.loc[i,'id'][-1])\n    df['id_last_str'] = id_laststr_list\n\n    study_len = df[df['id_last_str'] == 'y'].shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:55:15.285628Z","iopub.execute_input":"2021-06-17T02:55:15.286262Z","iopub.status.idle":"2021-06-17T02:55:15.354116Z","shell.execute_reply.started":"2021-06-17T02:55:15.286219Z","shell.execute_reply":"2021-06-17T02:55:15.353362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    !pip install /kaggle/input/kerasapplications -q\n    !pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n\n    import os\n\n    import efficientnet.tfkeras as efn\n    import numpy as np\n    import pandas as pd\n    import tensorflow as tf\n\n    def auto_select_accelerator():\n        try:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"Running on TPU:\", tpu.master())\n        except ValueError:\n            strategy = tf.distribute.get_strategy()\n        print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n        return strategy\n\n\n    def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n        def decode(path):\n            file_bytes = tf.io.read_file(path)\n            if ext == 'png':\n                img = tf.image.decode_png(file_bytes, channels=3)\n            elif ext in ['jpg', 'jpeg']:\n                img = tf.image.decode_jpeg(file_bytes, channels=3)\n            else:\n                raise ValueError(\"Image extension not supported\")\n\n            img = tf.cast(img, tf.float32) / 255.0\n            img = tf.image.resize(img, target_size)\n\n            return img\n\n        def decode_with_labels(path, label):\n            return decode(path), label\n\n        return decode_with_labels if with_labels else decode\n\n\n    def build_augmenter(with_labels=True):\n        def augment(img):\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            return img\n\n        def augment_with_labels(img, label):\n            return augment(img), label\n\n        return augment_with_labels if with_labels else augment\n\n\n    def build_dataset(paths, labels=None, bsize=32, cache=True,\n                      decode_fn=None, augment_fn=None,\n                      augment=True, repeat=True, shuffle=1024, \n                      cache_dir=\"\"):\n        if cache_dir != \"\" and cache is True:\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if decode_fn is None:\n            decode_fn = build_decoder(labels is not None)\n\n        if augment_fn is None:\n            augment_fn = build_augmenter(labels is not None)\n\n        AUTO = tf.data.experimental.AUTOTUNE\n        slices = paths if labels is None else (paths, labels)\n\n        dset = tf.data.Dataset.from_tensor_slices(slices)\n        dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n        dset = dset.cache(cache_dir) if cache else dset\n        dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n        dset = dset.repeat() if repeat else dset\n        dset = dset.shuffle(shuffle) if shuffle else dset\n        dset = dset.batch(bsize).prefetch(AUTO)\n\n        return dset\n\n    #COMPETITION_NAME = \"siim-cov19-test-img512-study-600\"\n    strategy = auto_select_accelerator()\n    BATCH_SIZE = strategy.num_replicas_in_sync * 16\n\n    IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n\n    #load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n    if fast_sub:\n        sub_df = fast_df.copy()\n    else:\n        sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n    sub_df = sub_df[:study_len]\n    test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'\n\n    sub_df['negative'] = 0\n    sub_df['typical'] = 0\n    sub_df['indeterminate'] = 0\n    sub_df['atypical'] = 0\n\n\n    label_cols = sub_df.columns[2:]\n\n    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')\n    dtest = build_dataset(\n        test_paths, bsize=BATCH_SIZE, repeat=False, \n        shuffle=False, augment=False, cache=False,\n        decode_fn=test_decoder\n    )\n\n    with strategy.scope():\n\n        models = []\n\n        models0 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-study/model0.h5'\n        )\n        models1 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-study/model1.h5'\n        )\n        models2 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-study/model2.h5'\n        )\n        models3 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-study/model3.h5'\n        )\n        models4 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-study/model4.h5'\n        )\n\n        models.append(models0)\n        models.append(models1)\n        models.append(models2)\n        models.append(models3)\n        models.append(models4)\n\n\n\n\n    sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)\n    tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T02:55:15.355419Z","iopub.execute_input":"2021-06-17T02:55:15.35579Z","iopub.status.idle":"2021-06-17T03:03:02.648767Z","shell.execute_reply.started":"2021-06-17T02:55:15.355753Z","shell.execute_reply":"2021-06-17T03:03:02.647686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 class","metadata":{}},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    if fast_sub:\n        sub_df_2 = fast_df.copy()\n    else:\n        sub_df_2 = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n    sub_df_2 = sub_df_2[study_len:]\n    test_paths = f'/kaggle/tmp/{split}/image/' + sub_df_2['id'] +'.png'\n    sub_df_2['none'] = 0\n\n    label_cols = sub_df_2.columns[2]\n\n    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[8], IMSIZE[8]), ext='png')\n    dtest = build_dataset(\n        test_paths, bsize=BATCH_SIZE, repeat=False, \n        shuffle=False, augment=False, cache=False,\n        decode_fn=test_decoder\n    )\n\n    with strategy.scope():\n\n        models = []\n\n        models0 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-fold0-5-2class/model0.h5'\n        )\n        models1 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-fold0-5-2class/model1.h5'\n        )\n        models2 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-fold0-5-2class/model2.h5'\n        )\n        models3 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-fold0-5-2class/model3.h5'\n        )\n        models4 = tf.keras.models.load_model(\n            '../input/siim-covid19-efnb7-train-fold0-5-2class/model4.h5'\n        )\n\n        models.append(models0)\n        models.append(models1)\n        models.append(models2)\n        models.append(models3)\n        models.append(models4)\n\n\n\n\n    sub_df_2[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)\n    df_2class = sub_df_2.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:03:02.652721Z","iopub.execute_input":"2021-06-17T03:03:02.653079Z","iopub.status.idle":"2021-06-17T03:08:23.467531Z","shell.execute_reply.started":"2021-06-17T03:03:02.653042Z","shell.execute_reply":"2021-06-17T03:08:23.466704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    del models\n    del models0, models1, models2, models3, models4\n    from numba import cuda\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:08:23.468946Z","iopub.execute_input":"2021-06-17T03:08:23.46933Z","iopub.status.idle":"2021-06-17T03:08:25.074864Z","shell.execute_reply.started":"2021-06-17T03:08:23.469263Z","shell.execute_reply":"2021-06-17T03:08:25.073969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:   \n    import sys\n    sys.path.append(\"../input/timm-pytorch-image-models/pytorch-image-models-master\")\n    import torch\n    from torch.utils.data import DataLoader, Dataset\n    import torch.nn as nn\n    import torch.nn.functional as F\n    from torchvision import transforms as T\n    from torchvision.transforms import functional as FV\n    #import segmentation_models_pytorch as smp\n    import torchvision\n    import albumentations, cv2\n    import timm\n    from tqdm import tqdm\n\n    label_cols = sub_df.columns[2:]\n\n    def get_path(idx):\n        if not ONLY_PUBLIC:\n            return f'/kaggle/tmp/{split}/study/' + idx +'.png'\n\n        return TEST_PATH + idx +'.png'\n\n\n    class SIIMDataset(Dataset):\n\n        def __init__(self, df, transforms=None, subset=\"train\", sat=True):\n\n            super().__init__()\n            self.df = df\n            self.transforms = transforms\n            self.subset = subset\n            self.sat = sat\n\n            if self.subset == \"train\":\n                self.df = self.df[~self.df[\"is_valid\"]]\n            elif self.subset == \"valid\":\n                self.df = self.df[self.df[\"is_valid\"]]\n\n        def __len__(self):\n            return len(self.df)\n\n        def __getitem__(self, idx):\n\n            row = self.df.iloc[idx]\n            img = cv2.imread(get_path(row.id))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            if self.sat:\n                img = T.functional.to_pil_image(img)\n                img = T.functional.adjust_saturation(img, 2)\n                img = np.array(img)\n\n            if self.transforms is not None:\n                img = self.transforms(image=img)[\"image\"]\n\n            img = FV.to_tensor(img)\n\n            if self.subset == \"test\":\n                return img\n            else:  \n                label = row[cls].astype('int').values\n                label = torch.as_tensor(label)   \n                return img, label.float()\n\n    def get_transform(image_size):\n\n        transforms_test = albumentations.Compose([\n        albumentations.Resize(image_size, image_size),\n        #albumentations.HueSaturationValue(p=1, hue_shift_limit=0, sat_shift_limit=(0.15,0.16), val_shift_limit=0),\n        albumentations.Normalize()])\n\n        return transforms_test\n\n\n    # def get_Unet(encoder_name, n_classes, pretrained=True):\n\n    #     aux_params=dict(\n    #     pooling='avg',             # one of 'avg', 'max'\n    #     dropout=0.5,               # dropout ratio, default is None\n    #     activation=None,      # activation function, default is None\n    #     classes=n_classes,                 # define number of output labels\n    #     )\n\n    #     if pretrained:\n    #         weights='imagenet'\n    #     else:\n    #         weights=None\n\n    #     model =  smp.UnetPlusPlus(\n    #                  encoder_name=encoder_name,\n    #                  encoder_weights=weights,\n    #                  in_channels=3,\n    #                  classes=1, \n    #                 aux_params=aux_params)\n    #     return model\n\n    # class CustomModelSeg(nn.Module):\n\n    #     def __init__(self, backbone, pretrained=False):\n    #         super().__init__()\n    #         self.backbone = backbone\n    #         self.unet = get_Unet(self.backbone, 4, pretrained=pretrained)\n\n    #     def forward(self, x, train=True):\n\n    #         if train:\n    #             return self.unet(x)\n\n    #         e = self.unet.encoder(x)[-1]\n    #         return self.unet.classification_head(e)\n\n    class CustomModel(nn.Module):\n\n        def __init__(self, backbone, pretrained=False):\n            super().__init__()\n            self.backbone = backbone\n            self.model = timm.create_model(backbone, pretrained=pretrained)\n\n            if \"res\" in self.backbone:\n                self.n_features = self.model.fc.in_features\n                self.model.fc = nn.Linear(self.n_features, 4)\n\n            elif \"vit\" in self.backbone:\n                self.n_features = self.head.fc.in_features\n                self.head.fc = nn.Linear(self.n_features, 4)\n\n            elif \"nfnet\" in self.backbone:\n                self.n_features = self.model.head.fc.in_features\n                self.model.head.fc = nn.Linear(self.n_features, 4)\n\n            elif \"ception\" in self.backbone:\n                self.n_features = self.model.last_linear.in_features\n                self.model.last_linear = nn.Linear(self.n_features, 4)\n\n            else:\n                self.n_features = self.model.classifier.in_features\n                self.model.classifier = nn.Linear(self.n_features, 4)\n\n\n        def forward(self, x):\n            h = self.model(x)\n            return h\n\n    class Model(nn.Module):\n\n        def __init__(self, backbone, num_classes, dropout=0.5, pretrained=True):\n            super(Model, self).__init__()\n\n            self.backbone = backbone\n            self.num_classes = num_classes\n            self.base = timm.create_model(self.backbone, pretrained=pretrained)\n            self.pooling = nn.AdaptiveAvgPool2d(1)\n            self.dropout = nn.Dropout(dropout)\n\n            if \"res\" in self.backbone:\n                self.myfc = nn.Linear(self.base.fc.in_features, self.num_classes)\n                self.base.fc = nn.Identity()\n\n            elif \"vit\" in self.backbone:\n                self.myfc = nn.Linear(self.base.head.in_features, self.num_classes)\n                self.base.head = nn.Identity()\n\n            elif \"ception\" in self.backbone:\n                self.myfc = nn.Linear(self.base.last_linear.in_features, self.num_classes)\n                self.base.global_pool = nn.Identity()\n                self.base.last_linear = nn.Identity()\n\n            elif \"efficient\" in self.backbone:\n                self.myfc = nn.Linear(self.base.classifier.in_features, self.num_classes)\n                self.base.classifier = nn.Identity()\n\n            else:\n                self.myfc = nn.Linear(self.base.classifier.in_features, self.num_classes)\n                self.base.global_pool = nn.Identity()\n                self.base.classifier = nn.Identity()\n\n        def extract(self, x):\n            return self.base(x)\n\n        def forward(self, x):\n\n            if \"efficient\" in self.backbone:\n                x = self.extract(x)\n                h = self.myfc(self.dropout(x))\n                return h\n            else:\n                bs = x.size(0)\n                features = self.base(x)\n                pooled_features = self.pooling(features).view(bs, -1)\n                output = self.myfc(pooled_features)\n                return output\n\n    def test_epoch(model, loader, bb=False):\n\n        model.eval()\n        PREDS = []\n\n        with torch.no_grad():\n            for data in tqdm(loader):\n                data = data.to(device)\n                if bb:\n                    logits = model(data, False)\n                else:\n                    logits = model(data)\n                act = nn.Softmax(dim=1)\n                PREDS.append(act(logits.cpu()).numpy())\n\n        return np.concatenate(np.array(PREDS))\n\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    ####################################################################################################\n    BASE = True\n\n    if BASE:\n\n        FOLDS = 5\n        image_sizes = [512]*FOLDS\n        batch_sizes = [16]*FOLDS\n\n        backbone = ['tf_efficientnet_b5',\n                    'tf_efficientnet_b5', \n                    'tf_efficientnet_b5',\n                    'tf_efficientnet_b5',\n                    'tf_efficientnet_b5']\n\n        pre_trained_weights = [\"../input/covid-new-fast/tf_efficientnet_b5_fold0_best_score.pth\",\n                               \"../input/covid-new-fast/tf_efficientnet_b5_fold1_best_score.pth\",\n                               \"../input/covid-new-fast/tf_efficientnet_b5_fold2_best_score.pth\",\n                               \"../input/covid-new-fast/tf_efficientnet_b5_fold3_best_score.pth\",\n                               \"../input/covid-new-fast/tf_efficientnet_b5_fold4_best_score.pth\"]\n\n        WGTS = [0.2]*FOLDS\n        PREDS_1 = np.zeros(shape=(len(sub_df), 4))\n\n        for fold in range(FOLDS):  \n\n            transforms_test = get_transform(image_sizes[fold])\n\n            dataset_test = SIIMDataset(sub_df, subset='test', transforms=transforms_test)\n\n            test_loader = DataLoader(dataset_test, \n                                       batch_size=batch_sizes[fold], \n                                       shuffle=False, \n                                       num_workers=2)\n\n            model = CustomModel(backbone=backbone[fold])\n\n            if pre_trained_weights[fold] is not None:\n                print(\"Loading Pretrained Weights.........\")\n                model.load_state_dict(torch.load(pre_trained_weights[fold])['model'])\n\n            model = model.to(device)\n\n            PREDS_1 += test_epoch(model, test_loader) * WGTS[fold]\n\n    ####################################################################################################\n\n    SEG = False    \n\n    if SEG:\n\n        FOLDS = 5\n        image_sizes = [512]*FOLDS\n        batch_sizes = [16]*FOLDS\n\n        backbone = ['efficientnet-b3',\n                    'efficientnet-b3', \n                    'efficientnet-b3',\n                    'efficientnet-b3',\n                    'efficientnet-b3']\n\n        pre_trained_weights = [\"../input/segmodelsuk/efficientnet-b3_fold0_best_loss.pth\",\n                               \"../input/segmodelsuk/efficientnet-b3_fold1_best_loss.pth\",\n                               \"../input/segmodelsuk/efficientnet-b3_fold2_best_loss.pth\",\n                               \"../input/segmodelsuk/efficientnet-b3_fold3_best_loss.pth\",\n                               \"../input/segmodelsuk/efficientnet-b3_fold4_best_loss.pth\"]\n\n\n        WGTS = [0.2]*FOLDS\n        PREDS_SEG = np.zeros(shape=(len(sub_df), 4))\n        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n        for fold in range(FOLDS):  \n\n            transforms_test = get_transform(image_sizes[fold])\n\n            dataset_test = SIIMDataset(sub_df, subset='test', transforms=transforms_test)\n\n            test_loader = DataLoader(dataset_test, \n                                       batch_size=batch_sizes[fold], \n                                       shuffle=False, \n                                       num_workers=2)\n\n            model = CustomModelSeg(backbone=backbone[fold])\n\n            if pre_trained_weights[fold] is not None:\n                print(\"Loading Pretrained Weights.........\")\n                model.load_state_dict(torch.load(pre_trained_weights[fold], map_location=device)['model'])\n\n            model = model.to(device)\n\n            PREDS_SEG += test_epoch(model, test_loader, True) * WGTS[fold]\n\n    #####################################################################################################    \n    FIRST = True\n\n    if FIRST:\n\n        PREDS_2 = np.zeros(shape=(len(sub_df), 4))\n        FOLDS = 3\n        image_sizes = [320, 320, 224]\n        batch_sizes = [32,32,32]\n\n        backbone = ['densenet169',\n                    'inception_v4', \n                    'tf_efficientnet_b5_ns']\n\n        pre_trained_weights = [\"../input/siimcovidpytorchdataset/models/densenet169_320_lr3e5_bs32_8epo_best_fold0.pth\",\n                               \"../input/siimcovidpytorchdataset/models/inception_v4_320_lr3e5_bs32_8epo_best_fold1.pth\",\n                               \"../input/siimcovidptmodels/tf_efficientnet_b5_ns_224_lr3e4_bs32_10epo_best_fold1.pth\"]\n\n        WGTS = [0.1, 0.2, 0.7]\n        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n        for fold in range(FOLDS): \n\n            transforms_test = get_transform(image_sizes[fold])\n\n            dataset_test = SIIMDataset(sub_df, subset='test', transforms=transforms_test, sat=False)\n\n            test_loader = DataLoader(dataset_test, \n                                       batch_size=batch_sizes[fold], \n                                       shuffle=False, \n                                       num_workers=2)\n\n            model = Model(backbone=backbone[fold], num_classes=4, pretrained=False)\n\n            if pre_trained_weights[fold] is not None:\n                print(\"Loading Pretrained Weights.........\")\n                model.load_state_dict(torch.load(pre_trained_weights[fold]))\n\n            model = model.to(device)\n\n            P = test_epoch(model, test_loader) * WGTS[fold]\n\n            if fold != 2:\n                temp = P[:,0].copy()\n                P[:,0] = P[:,1]\n                P[:,1] = temp\n\n            PREDS_2 += P\n\n    ####################################################################################################\n\n    full_preds = 0.5*PREDS_1 + 0.5*PREDS_2\n    sub_df[label_cols] = 0.3*sub_df[label_cols] + 0.7*full_preds","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:08:25.076441Z","iopub.execute_input":"2021-06-17T03:08:25.076786Z","iopub.status.idle":"2021-06-17T03:11:41.291271Z","shell.execute_reply.started":"2021-06-17T03:08:25.076749Z","shell.execute_reply":"2021-06-17T03:11:41.290288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    sub_df.columns = ['id', 'PredictionString1', 'negative', 'typical', 'indeterminate', 'atypical']\n    df = pd.merge(df, sub_df, on = 'id', how = 'left')\n\n    for i in range(study_len):\n        negative = df.loc[i,'negative']\n        typical = df.loc[i,'typical']\n        indeterminate = df.loc[i,'indeterminate']\n        atypical = df.loc[i,'atypical']\n        df.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\n\n    df_study = df[['id', 'PredictionString']]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:11:41.294365Z","iopub.execute_input":"2021-06-17T03:11:41.294636Z","iopub.status.idle":"2021-06-17T03:11:41.869908Z","shell.execute_reply.started":"2021-06-17T03:11:41.294607Z","shell.execute_reply":"2021-06-17T03:11:41.869049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:11:41.872315Z","iopub.execute_input":"2021-06-17T03:11:41.872674Z","iopub.status.idle":"2021-06-17T03:11:42.72506Z","shell.execute_reply.started":"2021-06-17T03:11:41.872636Z","shell.execute_reply":"2021-06-17T03:11:42.724131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# yolov5 predict","metadata":{}},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    import numpy as np, pandas as pd\n    from glob import glob\n    import shutil, os\n    import matplotlib.pyplot as plt\n    from sklearn.model_selection import GroupKFold\n    from tqdm.notebook import tqdm\n    import seaborn as sns\n    import torch","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:11:42.7271Z","iopub.execute_input":"2021-06-17T03:11:42.727761Z","iopub.status.idle":"2021-06-17T03:11:42.924937Z","shell.execute_reply.started":"2021-06-17T03:11:42.727719Z","shell.execute_reply":"2021-06-17T03:11:42.924112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    meta = meta[meta['split'] == 'test']\n    if fast_sub:\n        test_df = fast_df.copy()\n    else:\n        test_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\n    test_df = df[study_len:].reset_index(drop=True) \n    meta['image_id'] = meta['image_id'] + '_image'\n    meta['study_id'] = meta['study_id'] + '_study'\n    meta.columns = ['id', 'dim0', 'dim1', 'split', 'study_id']\n    test_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:11:42.926199Z","iopub.execute_input":"2021-06-17T03:11:42.926551Z","iopub.status.idle":"2021-06-17T03:11:42.948603Z","shell.execute_reply.started":"2021-06-17T03:11:42.926516Z","shell.execute_reply":"2021-06-17T03:11:42.947855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:    \n    !pip install ../input/ensembleboxes-offline-package/ensemble_boxes-1.0.4-py3-none-any.whl -q","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:11:42.980078Z","iopub.execute_input":"2021-06-17T03:11:42.980447Z","iopub.status.idle":"2021-06-17T03:12:09.638458Z","shell.execute_reply.started":"2021-06-17T03:11:42.980412Z","shell.execute_reply":"2021-06-17T03:12:09.637397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    #INPUT_PATH = '../input/siim-covid19-detection/'\n    OUTPUT_PATH = '/kaggle/working/'\n    SUBM_PATH = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:12:09.640189Z","iopub.execute_input":"2021-06-17T03:12:09.640574Z","iopub.status.idle":"2021-06-17T03:12:09.645835Z","shell.execute_reply.started":"2021-06-17T03:12:09.640532Z","shell.execute_reply":"2021-06-17T03:12:09.644998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:    \n    from ensemble_boxes import weighted_boxes_fusion\n\n\n    def ensemble(\n        subm_list,\n        iou_same=0.5,\n        out_path=None,\n        skip_box_thr=0.00000001,\n    ):\n        sizes = get_train_test_image_sizes()\n        preds = []\n        weights = []\n        checker = None\n        for df, weight in subm_list:\n            s = df.copy()\n            s.sort_values('id', inplace=True)\n            s.reset_index(drop=True, inplace=True)\n            ids = s['id']\n\n            if checker:\n                if tuple(ids) != checker:\n                    print(set(checker) - set(ids))\n                    print('Different IDS!', len(tuple(ids)), path)\n                    exit()\n            else:\n                checker = tuple(ids)\n\n            preds.append(s['PredictionString'].values)\n            weights.append(weight)\n\n        if out_path is None:\n            out_path = SUBM_PATH + 'ensemble_iou_{}.csv'.format(iou_same)\n            \n        out = open(out_path, 'w')\n        out.write('id,PredictionString\\n')\n        for j, id in enumerate(list(checker)):\n            #print(id)\n            boxes_list = []\n            scores_list = []\n            labels_list = []\n            empty = True\n            for i in range(len(preds)):\n                boxes = []\n                scores = []\n                labels = []\n                #print(preds[i])\n                p1 = preds[i][j]\n                if str(p1) != 'none 1 0 0 1 1':\n                    arr = p1.strip().split(' ')\n                    for k in range(0, len(arr), 6):\n                        cls = int(arr[k])\n                        prob = float(arr[k + 1])\n                        x1 = float(arr[k + 2]) / sizes[id][1]\n                        y1 = float(arr[k + 3]) / sizes[id][0]\n                        x2 = float(arr[k + 4]) / sizes[id][1]\n                        y2 = float(arr[k + 5]) / sizes[id][0]\n                        boxes.append([x1, y1, x2, y2])\n                        scores.append(prob)\n                        labels.append(cls)\n                    \n\n                boxes_list.append(boxes)\n                scores_list.append(scores)\n                labels_list.append(labels)\n\n            boxes, scores, labels = weighted_boxes_fusion(\n                boxes_list,\n                scores_list,\n                labels_list,\n                iou_thr=iou_same,\n                skip_box_thr=skip_box_thr,\n                weights=weights,\n                allows_overflow=True\n            )\n            #print(len(boxes), len(labels), len(scores))\n            #prior_2 = 1 - df_2class.query(f'id == \"{id}\"')[\"none\"]\n            #s_id = test_df.query(f'id == \"{id}\"')[\"study_id\"]\n            #prior_st = 1 - sub_df.query(f'id == \"{s_id}\"')[\"negative\"]\n            #prior = prior_2 #*0.5 + prior_st*0.5\n            if len(boxes) == 0:\n                out.write('{},none 1 0 0 1 1\\n'.format(id, ))\n            else:\n                final_str = ''\n                for i in range(len(boxes)):\n                    cls = int(labels[i])\n                    prob = float(scores[i])\n                    x1 = int(boxes[i][0] * sizes[id][1])\n                    y1 = int(boxes[i][1] * sizes[id][0])\n                    x2 = int(boxes[i][2] * sizes[id][1])\n                    y2 = int(boxes[i][3] * sizes[id][0])\n                    final_str += '{} {} {} {} {} {} '.format(cls, prob, x1, y1, x2, y2)\n                out.write('{},{}\\n'.format(id, final_str.strip()))\n\n        out.close()\n        return out_path\n\n\n    # def get_test_from_subm_list(subm_list):\n    #     out = []\n    #     for s, w in subm_list:\n    #         s1 = s.replace('_train', '_test')\n    #         out.append((s1, w))\n    #     return out\n\n    def get_train_test_image_sizes():\n        sizes = dict()\n        sizes_df = test_df.copy()\n        for index, row in sizes_df.iterrows():\n            sizes[row['id']] = (row['dim0'], row['dim1'])\n        return sizes\n\n\n    def ensemble_experiment_v4_yolo(preds_df_all):\n\n        subm_list = [\n            (preds_df_all[0], 1),\n            (preds_df_all[1], 1),\n            (preds_df_all[2], 1),\n            (preds_df_all[3], 1),\n            (preds_df_all[4], 1)\n        ]\n        #subm_list_test = get_test_from_subm_list(subm_list)\n\n        best_iou = 0.6\n        #out_path = SUBM_PATH + 'ensemble_yolo_standard.csv'.format(len(subm_list_test), best_iou)\n        predictions = ensemble(subm_list, best_iou)\n\n        return predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:48:10.737986Z","iopub.execute_input":"2021-06-17T03:48:10.738347Z","iopub.status.idle":"2021-06-17T03:48:10.758885Z","shell.execute_reply.started":"2021-06-17T03:48:10.738311Z","shell.execute_reply":"2021-06-17T03:48:10.757917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    dim = 512 #1024, 256, 'original'\n    test_dir = f'/kaggle/tmp/{split}/image'\n    weights_dir = ['/kaggle/input/siim-cov19-yolov5-train/yolov5/runs/train/exp/weights/best.pt',\n                   '/kaggle/input/covid-yolo-fold-1/yolov5/runs/train/exp/weights/best.pt',\n                   '/kaggle/input/covid-yolo-fold-2/yolov5/runs/train/exp/weights/best.pt',\n                   '/kaggle/input/covid-yolo-fold-3/yolov5/runs/train/exp/weights/best.pt',\n                   '/kaggle/input/covid-yolo-fold-4/yolov5/runs/train/exp/weights/best.pt']\n\n    shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\n    os.chdir('/kaggle/working/yolov5') # install dependencies\n\n    import torch\n    #from IPython.display import Image, clear_output  # to display images\n\n    #clear_output()\n    #print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n\n    #fold 0\n    wts = weights_dir[0]\n    !python detect.py --weights $wts\\\n    --img 512\\\n    --conf 0.001\\\n    --iou 0.5\\\n    --source $test_dir\\\n    --project /kaggle/working/yolov5_fold0/ --name test_iou_0.5_0.001\\\n    --save-txt --save-conf --exist-ok\n\n    #fold 1\n    wts = weights_dir[1]\n    !python detect.py --weights $wts\\\n    --img 512\\\n    --conf 0.001\\\n    --iou 0.5\\\n    --source $test_dir\\\n    --project /kaggle/working/yolov5_fold1/ --name test_iou_0.5_0.001\\\n    --save-txt --save-conf --exist-ok\n\n    #fold 2\n    wts = weights_dir[2]\n    !python detect.py --weights $wts\\\n    --img 512\\\n    --conf 0.001\\\n    --iou 0.5\\\n    --source $test_dir\\\n    --project /kaggle/working/yolov5_fold2/ --name test_iou_0.5_0.001\\\n    --save-txt --save-conf --exist-ok\n    \n    #fold 3\n    wts = weights_dir[3]\n    !python detect.py --weights $wts\\\n    --img 512\\\n    --conf 0.001\\\n    --iou 0.5\\\n    --source $test_dir\\\n    --project /kaggle/working/yolov5_fold3/ --name test_iou_0.5_0.001\\\n    --save-txt --save-conf --exist-ok\n    \n    #fold 4\n    wts = weights_dir[4]\n    !python detect.py --weights $wts\\\n    --img 512\\\n    --conf 0.001\\\n    --iou 0.5\\\n    --source $test_dir\\\n    --project /kaggle/working/yolov5_fold4/ --name test_iou_0.5_0.001\\\n    --save-txt --save-conf --exist-ok\n\n\n    def yolo2voc(image_height, image_width, bboxes):\n        \"\"\"\n        yolo => [xmid, ymid, w, h] (normalized)\n        voc  => [x1, y1, x2, y1]\n\n        \"\"\" \n        bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n        bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n        bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n        bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n        bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n        return bboxes\n\n    preds_df_all = []\n\n    for fold in range(5):\n\n        image_ids = []\n        PredictionStrings = []\n\n        for file_path in tqdm(glob('/kaggle/working/yolov5_fold{}/test_iou_0.5_0.001/labels/*.txt'.format(fold))):\n            image_id = file_path.split('/')[-1].split('.')[0]\n            w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n            f = open(file_path, 'r')\n            data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n            data = data[:, [0, 5, 1, 2, 3, 4]]\n            bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n            for idx in range(len(bboxes)):\n                bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n            image_ids.append(image_id)\n            PredictionStrings.append(' '.join(bboxes))\n            \n        full_df = test_df.copy().drop(['PredictionString'], axis=1)\n        preds_df = pd.DataFrame({'id':image_ids,'PredictionString':PredictionStrings})\n        preds_df_full = pd.merge(full_df, preds_df, on = 'id', how = 'left').fillna(\"none 1 0 0 1 1\")\n        preds_df_all.append(preds_df_full)\n\n    out_path = ensemble_experiment_v4_yolo(preds_df_all)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:13:47.606266Z","iopub.execute_input":"2021-06-17T03:13:47.60662Z","iopub.status.idle":"2021-06-17T03:21:52.675097Z","shell.execute_reply.started":"2021-06-17T03:13:47.606589Z","shell.execute_reply":"2021-06-17T03:21:52.674264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:    \n#     test_df = test_df.drop(['PredictionString'], axis=1)\n#     pred_df = pd.read_csv(out_path)\n#     sub_df = pd.merge(test_df, pred_df, on = 'id', how = 'left').fillna(\"none 1 0 0 1 1\")\n#     sub_df = sub_df[['id', 'PredictionString']]\n    sub_df = pd.read_csv(out_path)[['id', 'PredictionString']]\n    for i in range(sub_df.shape[0]):\n        if sub_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n            continue\n        sub_df_split = sub_df.loc[i,'PredictionString'].split()\n        sub_df_list = []\n        for j in range(int(len(sub_df_split) / 6)):\n            sub_df_list.append('opacity')\n            sub_df_list.append(sub_df_split[6 * j + 1])\n            sub_df_list.append(sub_df_split[6 * j + 2])\n            sub_df_list.append(sub_df_split[6 * j + 3])\n            sub_df_list.append(sub_df_split[6 * j + 4])\n            sub_df_list.append(sub_df_split[6 * j + 5])\n        sub_df.loc[i,'PredictionString'] = ' '.join(sub_df_list)\n    sub_df['none'] = df_2class['none'] \n    for i in range(sub_df.shape[0]):\n        if sub_df.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n            sub_df.loc[i,'PredictionString'] = sub_df.loc[i,'PredictionString'] + ' none ' + \\\n            str(sub_df.loc[i,'none']) + ' 0 0 1 1'\n    sub_df = sub_df[['id', 'PredictionString']]   \n    df_study = df_study[:study_len]\n    df_study = df_study.append(sub_df).reset_index(drop=True)\n    df_study.to_csv('/kaggle/working/submission.csv',index = False)  \n    shutil.rmtree('/kaggle/working/yolov5')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:48:50.320017Z","iopub.execute_input":"2021-06-17T03:48:50.320373Z","iopub.status.idle":"2021-06-17T03:48:51.107706Z","shell.execute_reply.started":"2021-06-17T03:48:50.320338Z","shell.execute_reply":"2021-06-17T03:48:51.106836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not ONLY_PUBLIC:\n    !rm -rf /kaggle/working/yolov5_fold0\n    !rm -rf /kaggle/working/yolov5_fold1\n    !rm -rf /kaggle/working/yolov5_fold2\n    !rm -rf /kaggle/working/yolov5_fold3\n    !rm -rf /kaggle/working/yolov5_fold4\n    os.remove('/kaggle/working/ensemble_iou_0.3.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:38:53.700726Z","iopub.execute_input":"2021-06-17T03:38:53.701053Z","iopub.status.idle":"2021-06-17T03:38:57.694217Z","shell.execute_reply.started":"2021-06-17T03:38:53.701023Z","shell.execute_reply":"2021-06-17T03:38:57.693204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ONLY_PUBLIC:\n    sub_df = pd.read_csv(\"../input/siim-covid19-detection/sample_submission.csv\")\n    pred_sub = pd.read_csv(\"../input/siim-covid19-detection/sample_submission.csv\")[0:100]\n    for i in range(len(sub_df)):\n        if not sub_df.loc[i, \"id\"].isin(pred_sub[\"id\"]): \n            continue\n        sub_df.loc[i, \"PredictionString\"]=pred_sub.query(f'id == \"{sub_df.loc[i, \"id\"]}\"')[\"PredictionString\"]        ","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:48:54.923665Z","iopub.execute_input":"2021-06-17T03:48:54.923984Z","iopub.status.idle":"2021-06-17T03:48:54.930817Z","shell.execute_reply.started":"2021-06-17T03:48:54.923954Z","shell.execute_reply":"2021-06-17T03:48:54.92967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_study","metadata":{"execution":{"iopub.status.busy":"2021-06-17T03:48:56.364797Z","iopub.execute_input":"2021-06-17T03:48:56.365113Z","iopub.status.idle":"2021-06-17T03:48:56.391877Z","shell.execute_reply.started":"2021-06-17T03:48:56.365083Z","shell.execute_reply":"2021-06-17T03:48:56.386113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}