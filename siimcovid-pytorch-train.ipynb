{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q /kaggle/input/iterative-stratification/iterative-stratification-master\n!pip -q install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-29T23:25:05.491819Z","iopub.execute_input":"2021-05-29T23:25:05.492093Z","iopub.status.idle":"2021-05-29T23:25:21.555498Z","shell.execute_reply.started":"2021-05-29T23:25:05.492033Z","shell.execute_reply":"2021-05-29T23:25:21.554459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/timm-pytorch-image-models/pytorch-image-models-master\")\nfrom fastai.vision.all import *\nimport os, gc\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport subprocess\nimport cv2\nimport PIL.Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom pylab import rcParams\nimport seaborn as sns\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.transforms import functional as FV\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom warmup_scheduler import GradualWarmupScheduler\nimport albumentations\nimport timm\nfrom tqdm import tqdm\nimport torch.cuda.amp as amp\nimport warnings\n\nwarnings.simplefilter('ignore')\nscaler = amp.GradScaler()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:21.557195Z","iopub.execute_input":"2021-05-29T23:25:21.557541Z","iopub.status.idle":"2021-05-29T23:25:26.701563Z","shell.execute_reply.started":"2021-05-29T23:25:21.557502Z","shell.execute_reply":"2021-05-29T23:25:26.700504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Python        : ' + sys.version.split('\\n')[0])\nprint('Numpy         : ' + np.__version__)\nprint('Pandas        : ' + pd.__version__)\nprint('PyTorch       : ' + torch.__version__)\nprint('Albumentations: ' + albumentations.__version__)\nprint('Timm          : ' + timm.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.703544Z","iopub.execute_input":"2021-05-29T23:25:26.703822Z","iopub.status.idle":"2021-05-29T23:25:26.713089Z","shell.execute_reply.started":"2021-05-29T23:25:26.703777Z","shell.execute_reply":"2021-05-29T23:25:26.711424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls = [\"Negative for Pneumonia\", \"Typical Appearance\", \"Indeterminate Appearance\", \"Atypical Appearance\"]\n\nclass cfg:\n    \n    debug = False\n    seed = 42\n    nfold = 5\n    num_classes = 4\n    siamese_nfeatures = 128\n    \n    train = True\n    analyze = False\n    pretrained = True\n    over_sample = False\n    rand_aug = False\n    multi_head = False\n    freeze = False\n    heads = [2,2]\n    mode = \"all\"\n    \n    folds = 3\n    dim = [320, 320, 224]\n    batch_size = [32, 32, 32]\n    valid_fold = [3, 2, 4]\n    aggresive_aug = [False,False,False]\n    \n    # MODELS\n    \n    WGTS = [0.3,0.7]\n    \n    kernel_type = ['densenet169_320_lr3e5_bs32_10epo', \n                   'inception_v4_320_lr3e5_bs32_10epo',\n                   'tf_efficientnet_b5_ns_224_lr3e5_bs32_10epo']\n\n    backbone = ['densenet169',\n                'inception_v4',\n                'tf_efficientnet_b5_ns']\n    \n    base_weights = [None,\n                    None]\n    \n    #base_weights = [None,None]\n    \n    pre_trained_weights = [\"../input/siimcovidpytorchdataset/models/densenet169_320_lr3e5_bs32_8epo_best_fold0.pth\",\n                           \"../input/siimcovidpytorchdataset/models/inception_v4_320_lr3e5_bs32_8epo_best_fold1.pth\",\n                           \"../input/siimcovidptmodels/tf_efficientnet_b5_ns_224_lr3e4_bs32_10epo_best_fold1.pth\"]\n    \n    #pre_trained_weights = [None,None,None]\n    \n    if mode == \"binary\":\n        num_classes = 2\n    \n    # Other\n    \n    num_workers = 2\n    warmup_epo = 2\n    init_lr = 3e-5\n    cosine_epo = 3 if not debug else 1\n    n_epochs = warmup_epo + cosine_epo\n    loss_weights = [1., 9.]\n    log_dir = './logs'\n    model_dir = './models'\n    \nos.makedirs(cfg.log_dir, exist_ok=True)\nos.makedirs(cfg.model_dir, exist_ok=True)\nkt_full = ''\nfor kt in cfg.kernel_type:\n    kt_full += (\"_\"+kt) \nlog_file = os.path.join(cfg.log_dir, f'log{kt_full}.txt')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:31:46.989569Z","iopub.execute_input":"2021-05-29T23:31:46.989922Z","iopub.status.idle":"2021-05-29T23:31:47.003157Z","shell.execute_reply.started":"2021-05-29T23:31:46.989889Z","shell.execute_reply":"2021-05-29T23:31:47.002140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False # set True to be faster\n    print(f'Setting all seeds to be {seed} to reproduce...')\nseed_everything(cfg.seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:31:48.007061Z","iopub.execute_input":"2021-05-29T23:31:48.007405Z","iopub.status.idle":"2021-05-29T23:31:48.013752Z","shell.execute_reply.started":"2021-05-29T23:31:48.007376Z","shell.execute_reply":"2021-05-29T23:31:48.012626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def over_sample(df_train, labels, anchor):\n    \n    df = df_train.copy()\n    for l in labels:\n        df_lbl = df[df[l] == 1]\n        r = len(df[df[anchor]==1])//len(df_lbl)\n        for _ in range(r):\n            df = df.append(df_lbl, ignore_index = True)\n        \n    return df\n\ndf_train = pd.read_csv(\"../input/siimcovid19-512-jpg-image-dataset/train.csv\")\ndf_train[\"image_path\"] = \"../input/siimcovid19-512-jpg-image-dataset/train/\" + df_train[\"image_id\"] + \".jpg\"\n\nif cfg.train and cfg.over_sample:\n    df_train = over_sample(df_train, cls[1:], cls[0])\n\ndf_train[\"class_name\"] = np.argmax(df_train[cls].values, axis=1)\nprint(df_train.class_name.value_counts())\n\ny = df_train[cls].values\nX = df_train['image_id'].values\n\ndf_train['fold'] = np.nan\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf = MultilabelStratifiedKFold(n_splits=cfg.nfold, random_state=cfg.seed, shuffle=True)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    df_train.iloc[test_index, -1] = i\n    \ndf_train['fold'] = df_train['fold'].astype('int')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:32:33.380806Z","iopub.execute_input":"2021-05-29T23:32:33.381182Z","iopub.status.idle":"2021-05-29T23:32:33.682664Z","shell.execute_reply.started":"2021-05-29T23:32:33.381148Z","shell.execute_reply":"2021-05-29T23:32:33.681699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cfg.mode == \"binary\":\n    df_train[\"others\"] = 1\n    df_train[\"others\"][df_train[\"Negative for Pneumonia\"] == 1] = 0\n    if not cfg.analyze:\n        cls = [\"Negative for Pneumonia\", \"others\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.972906Z","iopub.status.idle":"2021-05-29T23:25:26.973283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cfg.debug:\n    df_train = df_train[0:10]\n    \ndef split_data(vld_fold):\n    df_train[\"is_valid\"] = False\n    df_train[\"is_valid\"][df_train[\"fold\"] == vld_fold] = True\n    df_train[cls] = df_train[cls].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.974334Z","iopub.status.idle":"2021-05-29T23:25:26.97481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def randAugment(N, M, dim=256, p=0.5):\n\n    shift_x = np.linspace(0,150,10)\n    shift_y = np.linspace(0,150,10)\n    rot = np.linspace(0,30,10)\n    shear = np.linspace(0,10,10)\n    sola = np.linspace(0,256,10)\n    post = [4,4,5,5,6,6,7,7,8,8]\n    cont = [np.linspace(-0.8,-0.1,10),np.linspace(0.1,2,10)]\n    bright = np.linspace(0.1,0.7,10)\n    shar = np.linspace(0.1,0.9,10)\n    cut = np.linspace(0.05,0.1,10)\n\n    Aug = [albumentations.ShiftScaleRotate(shift_limit_x=shift_x[M], rotate_limit=0, shift_limit_y=0, shift_limit=shift_x[M], p=p),\n        albumentations.ShiftScaleRotate(shift_limit_y=shift_y[M], rotate_limit=0, shift_limit_x=0, shift_limit=shift_y[M], p=p),\n        albumentations.IAAAffine(rotate=rot[M], p=p),\n        albumentations.IAAAffine(shear=shear[M], p=p),\n        albumentations.InvertImg(p=p),\n        albumentations.Equalize(p=p),\n        albumentations.Solarize(threshold=sola[M], p=p),\n        albumentations.Posterize(num_bits=post[M], p=p),\n        albumentations.RandomContrast(limit=[cont[0][M], cont[1][M]], p=p),\n        albumentations.RandomBrightness(limit=bright[M], p=p),\n        albumentations.IAASharpen(alpha=shar[M], lightness=shar[M], p=p),\n        albumentations.Cutout(num_holes=8, max_h_size=int(cut[M]*dim), max_w_size=int(cut[M]*dim), p=p)]\n\n    ops = np.random.choice(Aug, N)\n    ops = np.append(ops, [albumentations.Resize(dim, dim), albumentations.Normalize()])\n    transforms = albumentations.Compose(ops)\n    \n    return transforms\n\n\ndef get_transforms(image_size, aggresive=True, rand=False, M=3, N=2, P=0.7):\n    \n    transforms_train_aggresive = albumentations.Compose([\n        albumentations.Transpose(p=0.3),\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.RandomBrightness(limit=0.2, p=0.75),\n        albumentations.RandomContrast(limit=0.2, p=0.75),\n        \n        albumentations.OneOf([\n            albumentations.MotionBlur(blur_limit=5),\n            albumentations.MedianBlur(blur_limit=5),\n            albumentations.GaussianBlur(blur_limit=5),\n            albumentations.GaussNoise(var_limit=(5.0, 30.0)),\n        ], p=0.5),\n\n        albumentations.OneOf([\n            albumentations.OpticalDistortion(distort_limit=1.0),\n            albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n            albumentations.ElasticTransform(alpha=3),\n        ], p=0.5),\n\n        albumentations.CLAHE(clip_limit=4.0, p=0.7),\n        albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),    \n        albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n        albumentations.Resize(image_size, image_size),\n        albumentations.Cutout(max_h_size=int(image_size * 0.12), max_w_size=int(image_size * 0.12), num_holes=10, p=0.7),\n        albumentations.Normalize()\n    ])\n    \n    \n    transforms_train = albumentations.Compose([\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.HorizontalFlip(p=0.5),\n#         albumentations.RandomBrightness(limit=0.2, p=0.65),\n#         albumentations.RandomContrast(limit=0.2, p=0.65),\n#         albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.65),\n        albumentations.Resize(image_size, image_size),\n        albumentations.Cutout(max_h_size=int(image_size * 0.12), max_w_size=int(image_size * 0.12), num_holes=3, p=0.5),\n        albumentations.Normalize()\n    ])\n    \n    transforms_val = albumentations.Compose([\n        albumentations.Resize(image_size, image_size),\n        albumentations.Normalize()\n    ])\n    \n    if rand:\n        return randAugment(N, M, image_size, P), transforms_val\n    \n    return transforms_train_aggresive if aggresive else transforms_train, transforms_val","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.975882Z","iopub.status.idle":"2021-05-29T23:25:26.97644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SIIMDataset(Dataset):\n    \n    def __init__(self, df, transforms=None, subset=\"train\"):\n        \n        super().__init__()\n        self.df = df\n        self.transforms = transforms\n        self.subset = subset\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n            \n        row = self.df.iloc[idx]\n        img = cv2.imread(row.image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms is not None:\n            img = self.transforms(image=img)[\"image\"]\n            \n        img = FV.to_tensor(img) \n        \n        if self.subset == \"test\":\n            return img\n        else:  \n            label = row[cls].astype('int').values\n            label = torch.as_tensor(label)   \n            return img, label.float()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.977597Z","iopub.status.idle":"2021-05-29T23:25:26.97819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms_train, transforms_valid = get_transforms(320, cfg.aggresive_aug[0], rand=cfg.rand_aug)\ntransforms_train","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.979284Z","iopub.status.idle":"2021-05-29T23:25:26.979844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_data(0)\nds = SIIMDataset(df=df_train, transforms=transforms_train, subset=\"train\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.981205Z","iopub.status.idle":"2021-05-29T23:25:26.981764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rcParams['figure.figsize'] = 15,5\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = i*5 + p\n        img, label = ds[idx]\n        axarr[p].imshow(img.transpose(0,1).transpose(1,2).squeeze())\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.982957Z","iopub.status.idle":"2021-05-29T23:25:26.983512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_activation(activ_name: str=\"relu\"):\n\n    act_dict = {\"relu\": nn.ReLU(inplace=True),\n                \"tanh\": nn.Tanh(),\n                \"sigmoid\": nn.Sigmoid(),\n                \"identity\": nn.Identity()}\n    \n    if activ_name in act_dict:\n        return act_dict[activ_name]\n    else:\n        raise NotImplementedError\n        \nclass Conv2dBNActiv(nn.Module):\n    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n    \n    def __init__(\n        self, in_channels: int, out_channels: int,\n        kernel_size: int, stride: int=1, padding: int=0,\n        bias: bool=False, use_bn: bool=True, activ: str=\"relu\"\n    ):\n        \"\"\"\"\"\"\n        super(Conv2dBNActiv, self).__init__()\n        layers = []\n        layers.append(nn.Conv2d(\n            in_channels, out_channels,\n            kernel_size, stride, padding, bias=bias))\n        if use_bn:\n            layers.append(nn.BatchNorm2d(out_channels))\n            \n        layers.append(get_activation(activ))\n        self.layers = nn.Sequential(*layers)\n        \n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        return self.layers(x)\n    \nclass SSEBlock(nn.Module):\n    \"\"\"channel `S`queeze and `s`patial `E`xcitation Block.\"\"\"\n\n    def __init__(self, in_channels: int):\n        \"\"\"Initialize.\"\"\"\n        super(SSEBlock, self).__init__()\n        self.channel_squeeze = nn.Conv2d(\n            in_channels=in_channels, out_channels=1,\n            kernel_size=1, stride=1, padding=0, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        \"\"\"Forward.\"\"\"\n        # # x: (bs, ch, h, w) => h: (bs, 1, h, w)\n        h = self.sigmoid(self.channel_squeeze(x))\n        # # x, h => return: (bs, ch, h, w)\n        return x * h\n    \n    \nclass SpatialAttentionBlock(nn.Module):\n    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n    \n    def __init__(\n        self, in_channels: int,\n        out_channels_list,\n    ):\n        \"\"\"Initialize\"\"\"\n        super(SpatialAttentionBlock, self).__init__()\n        self.n_layers = len(out_channels_list)\n        channels_list = [in_channels] + out_channels_list\n        assert self.n_layers > 0\n        assert channels_list[-1] == 1\n        \n        for i in range(self.n_layers - 1):\n            in_chs, out_chs = channels_list[i: i + 2]\n            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n            setattr(self, f\"conv{i + 1}\", layer)\n            \n        in_chs, out_chs = channels_list[-2:]\n        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n        setattr(self, f\"conv{self.n_layers}\", layer)\n        \n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        h = x\n        for i in range(self.n_layers):\n            h = getattr(self, f\"conv{i + 1}\")(h)\n            \n        h = h * x\n        return h\n    \nclass SingleHeadModel(nn.Module):\n    \n    def __init__(\n        self, base_name: str='resnext50_32x4d', out_dim: int=11, pretrained=False\n    ):\n        \"\"\"\"\"\"\n        self.base_name = base_name\n        super(SingleHeadModel, self).__init__()\n        \n        # # load base model\n        base_model = timm.create_model(base_name, pretrained=pretrained)\n        in_features = base_model.num_features\n        \n        # # remove global pooling and head classifier\n        # base_model.reset_classifier(0, '')\n        base_model.reset_classifier(0)\n        \n        # # Shared CNN Bacbone\n        self.backbone = base_model\n        \n        # # Single Heads.\n        self.head_fc = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, out_dim))\n\n    def forward(self, x):\n        \"\"\"\"\"\"\n        h = self.backbone(x)\n        h = self.head_fc(h)\n        return h\n    \nclass MultiHeadModel(nn.Module):\n    \n    def __init__(self, base_name, out_dims_head, weights=None):\n        \n        super(MultiHeadModel, self).__init__()\n        self.base_name = base_name\n        self.weights = weights\n        self.n_heads = len(out_dims_head)\n        \n        # # load base model\n        if  not isinstance(self.base_name, str):\n            base_model = self.base_name\n\n            if self.weights is not None:\n                base_model.load_state_dict(torch.load(self.weights))\n\n            in_features = base_model.myfc.in_features\n            base_model.base.global_pool.flatten = False\n            base_model.dropout = nn.Identity()\n            base_model.myfc = nn.Identity()\n        else:\n            base_model = timm.create_model(base_name, pretrained=cfg.pretrained)\n            in_features = base_model.num_features\n            base_model.reset_classifier(0, '')\n        \n        # # Shared CNN Bacbone\n        self.backbone = base_model\n        \n        for i, out_dim in enumerate(out_dims_head):\n            layer_name = f\"head_{i}\"\n            layer = nn.Sequential(\n                SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n                nn.AdaptiveAvgPool2d(output_size=1),\n                nn.Flatten(start_dim=1),\n                nn.Linear(in_features, in_features),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.5),\n                nn.Linear(in_features, out_dim))\n            setattr(self, layer_name, layer)\n\n    def forward(self, x):\n        \"\"\"\"\"\"\n        h = self.backbone(x)\n        hs = [\n            getattr(self, f\"head_{i}\")(h) for i in range(self.n_heads)]\n        y = torch.cat(hs, axis=1)\n        return y\n\n\nclass Model(nn.Module):\n    \n    def __init__(self, backbone, num_classes, dropout=0.5, pretrained=True):\n        super(Model, self).__init__()\n        \n        self.backbone = backbone\n        self.num_classes = num_classes\n        self.base = timm.create_model(self.backbone, pretrained=pretrained)\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(dropout)\n        \n        if \"res\" in self.backbone:\n            self.myfc = nn.Linear(self.base.fc.in_features, self.num_classes)\n            self.base.global_pool = nn.Identity()\n            self.base.fc = nn.Identity()\n            \n        elif \"vit\" in self.backbone:\n            self.myfc = nn.Linear(self.base.head.in_features, self.num_classes)\n            self.base.global_pool = nn.Identity()\n            self.base.head = nn.Identity()\n            \n        elif \"nfnet\" in self.backbone:\n            self.myfc = nn.Linear(self.base.head.fc.in_features, self.num_classes)\n            self.base.global_pool = nn.Identity()\n            self.base.head.fc = nn.Identity()\n            \n        elif \"ception\" in self.backbone:\n            self.myfc = nn.Linear(self.base.last_linear.in_features, self.num_classes)\n            self.base.global_pool = nn.Identity()\n            self.base.last_linear = nn.Identity()\n        \n        elif \"efficient\" in self.backbone:\n            self.myfc = nn.Linear(self.base.classifier.in_features, self.num_classes)\n            self.base.classifier = nn.Identity()\n            \n        else:\n            self.myfc = nn.Linear(self.base.classifier.in_features, self.num_classes)\n            self.base.global_pool = nn.Identity()\n            self.base.classifier = nn.Identity()\n            \n        if cfg.freeze:\n            for param in self.base.parameters():\n                param.requires_grad = False\n        else:\n            for param in self.base.parameters():\n                param.requires_grad = True\n        \n\n    def extract(self, x):\n            return self.base(x)\n\n    def forward(self, x):\n\n        if \"efficient\" in self.backbone:\n            x = self.extract(x)\n            h = self.myfc(self.dropout(x))\n            return h\n        else:\n            bs = x.size(0)\n            features = self.base(x)\n            pooled_features = self.pooling(features).view(bs, -1)\n            output = self.myfc(pooled_features)\n            return output\n    \nclass SiameseModel(nn.Module):\n    \n    def __init__(self, model, pretrained=True, weights=None, dropout=0.5):\n        super(SiameseModel, self).__init__()\n        \n        self.model = model\n        self.weights = weights\n        self.dropout = nn.Dropout(dropout)\n        \n        if self.weights is None:\n            \n            self.base = timm.create_model(self.model, pretrained=pretrained)\n            \n            if \"res\" in self.backbone:\n                self.myfc = nn.Linear(self.base.fc.in_features, cfg.siamese_nfeatures)\n                self.base.fc = nn.Identity()\n\n            elif \"vit\" in self.backbone:\n                self.myfc = nn.Linear(self.base.head.in_features, cfg.siamese_nfeatures)\n                self.base.head = nn.Identity()\n\n            elif \"nfnet\" in self.backbone:\n                self.myfc = nn.Linear(self.base.head.fc.in_features, cfg.siamese_nfeatures)\n                self.base.head.fc = nn.Identity()\n\n            else:\n                self.myfc = nn.Linear(self.base.classifier.in_features, cfg.siamese_nfeatures)\n                self.base.classifier = nn.Identity()\n                \n        else:\n            self.base = self.model\n            self.base.load_state_dict(torch.load(self.weights, map_location=device))\n            self.base.dropout = nn.Identity()\n            self.myfc = nn.Linear(self.base.myfc.in_features, cfg.siamese_nfeatures)\n            self.base.myfc = nn.Identity()\n            \n        \n    def extract(self, x):\n        return self.base(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        e = self.myfc(self.dropout(x))\n        return e","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.984785Z","iopub.status.idle":"2021-05-29T23:25:26.985364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = Model(backbone=cfg.backbone[2], num_classes=cfg.num_classes)\nx = torch.stack([ds[i][0] for i in range(2)])\ny = m(x)\ny.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.986508Z","iopub.status.idle":"2021-05-29T23:25:26.987091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n        \n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\noptimizer = optim.Adam(m.parameters(), lr=cfg.init_lr)\nscheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cfg.cosine_epo)\nscheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, \n                                            total_epoch=cfg.warmup_epo, \n                                            after_scheduler=scheduler_cosine)\nlrs = []\nfor epoch in range(1, cfg.n_epochs+1):\n    scheduler_warmup.step(epoch-1)\n    lrs.append(optimizer.param_groups[0][\"lr\"])\nrcParams['figure.figsize'] = 20,3\nplt.plot(lrs)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.988281Z","iopub.status.idle":"2021-05-29T23:25:26.98884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer, criterion):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, targets) in bar:\n\n        optimizer.zero_grad()\n        data, targets = data.to(device), targets.to(device)\n\n        with amp.autocast():\n            logits = model(data)\n            loss = criterion(logits, targets)\n            \n        scaler.scale(loss).backward() \n        scaler.step(optimizer)\n        scaler.update()\n\n        loss_np = loss.item()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-50:]) / min(len(train_loss), 50)\n        bar.set_description('loss: %.4f, smth: %.4f' % (loss_np, smooth_loss))\n\n    return np.mean(train_loss)\n\n\ndef valid_epoch(model, loader, get_output=False):\n\n    model.eval()\n    val_loss = []\n    PREDS = []\n    LOGITS = []\n    TARGETS = []\n    \n    with torch.no_grad():\n        for (data, targets) in tqdm(loader):\n            data, targets = data.to(device), targets.to(device)\n            logits = model(data)\n            loss = criterion(logits, targets)\n            val_loss.append(loss.item())\n            LOGITS.append(logits.cpu())\n            act = nn.Softmax(dim=1)\n            \n            PREDS.append(F.one_hot(torch.argmax(act(logits.cpu()), dim=1), \n                                   num_classes=cfg.num_classes).numpy().astype(int))\n            \n            TARGETS.append(targets.cpu().numpy().astype(int))\n            \n    val_loss = np.mean(val_loss)\n    PREDS = np.concatenate(np.array(PREDS))\n    TARGETS = np.concatenate(np.array(TARGETS))\n\n    if get_output:\n        return LOGITS\n    else:\n        acc = accuracy_score(TARGETS[:-1], PREDS[:-1])\n        \n        try:\n            auc = roc_auc_score(TARGETS[:-1], PREDS[:-1])\n        except:\n            auc = 0.0\n        \n        return val_loss,acc,auc\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.989957Z","iopub.status.idle":"2021-05-29T23:25:26.990527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(fold):\n    \n    content = 'Fold: ' + str(fold)\n    print(content)\n    with open(log_file, 'a') as appender:\n        appender.write(content + '\\n')\n        \n    split_data(cfg.valid_fold[fold])\n        \n    train_ = df_train[~df_train[\"is_valid\"]].copy()\n    valid_ = df_train[df_train[\"is_valid\"]].copy()\n    \n    transforms_train, transforms_valid = get_transforms(cfg.dim[fold], cfg.aggresive_aug[fold], rand=cfg.rand_aug)\n    \n    dataset_train = SIIMDataset(train_, subset='train', transforms=transforms_train)\n    dataset_valid = SIIMDataset(valid_, subset='valid', transforms=transforms_valid)\n    \n    train_loader = DataLoader(dataset_train, \n                               batch_size=cfg.batch_size[fold], \n                               shuffle=True, \n                               num_workers=cfg.num_workers)\n    \n    valid_loader = DataLoader(dataset_valid, \n                               batch_size=cfg.batch_size[fold], \n                               shuffle=False, \n                               num_workers=cfg.num_workers)\n    \n    if cfg.multi_head: \n        if cfg.base_weights[fold] is not None:\n            base_model = Model(backbone=cfg.backbone[fold], num_classes=cfg.num_classes, pretrained=cfg.pretrained)\n            model = MultiHeadModel(base_model, cfg.heads, cfg.base_weights[fold])\n        else:\n            model = MultiHeadModel(cfg.backbone[fold], cfg.heads)\n    else:\n        model = Model(backbone=cfg.backbone[fold], num_classes=cfg.num_classes, pretrained=cfg.pretrained)\n        \n    if cfg.pre_trained_weights[fold] is not None:\n        print(\"Loading Pretrained Weights.........\")\n        model.load_state_dict(torch.load(cfg.pre_trained_weights[fold]))\n    \n    model = model.to(device)\n    loss_min = 10000\n    model_file = os.path.join(cfg.model_dir, f'{cfg.kernel_type[fold]}_best_fold{fold}.pth')\n\n    optimizer = optim.Adam(model.parameters(), lr=cfg.init_lr)\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, cfg.cosine_epo)\n    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=cfg.warmup_epo, \n                                                after_scheduler=scheduler_cosine)\n    \n    for epoch in range(1, cfg.n_epochs+1):\n        print(time.ctime(), 'Epoch:', epoch)\n        scheduler_warmup.step(epoch-1)\n        \n        gc.collect()\n        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n        \n        gc.collect()\n        val_loss, acc, auc = valid_epoch(model, valid_loader)\n\n        content = time.ctime() + ' ' + f'Fold {fold} Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, \\\n                    train loss: {train_loss:.4f}, valid loss: {(val_loss):.4f}, acc: {acc:.4f} auc: {auc:.4f}.'\n        \n        print(content)\n        with open(log_file, 'a') as appender:\n            appender.write(content + '\\n')\n            \n        if loss_min > val_loss:\n            print('Val Loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(loss_min, val_loss))\n            torch.save(model.state_dict(), model_file)\n            loss_min = val_loss\n    \n    if cfg.multi_head:\n        torch.save(model.state_dict(), os.path.join(cfg.model_dir, f'{cfg.kernel_type[fold]}_multihead.pth'))\n    else:\n        torch.save(model.state_dict(), os.path.join(cfg.model_dir, f'{cfg.kernel_type[fold]}.pth'))\n        \n    torch.cuda.empty_cache()   ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.991733Z","iopub.status.idle":"2021-05-29T23:25:26.992337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FocalCosineLoss(nn.Module):\n    \n    def __init__(self, alpha = 1, gamma = 2, xent = 0.1, reduction = \"mean\"):\n        super(FocalCosineLoss, self).__init__()\n        self.alpha     = alpha\n        self.gamma     = gamma\n        self.xent      = xent\n        self.reduction = reduction\n        self.y         = torch.Tensor([1]).to(device)\n        \n    def forward(self, input, target):\n        cosine_loss = F.cosine_embedding_loss(input, target, self.y, reduction = self.reduction)\n        cent_loss   = nn.BCEWithLogitsLoss()(input, target)\n        pt          = torch.exp(-cent_loss)\n        focal_loss  = self.alpha * (1-pt)**self.gamma * cent_loss\n\n        if self.reduction == \"mean\":\n            focal_loss = torch.mean(focal_loss)\n        \n        return cosine_loss + self.xent * focal_loss\n    \nclass ContrastiveLoss(torch.nn.Module):\n    \"\"\"\n    Contrastive loss function.\n    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n    \"\"\"\n\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, dist, label):\n\n        loss = torch.mean(1/2*(label) * torch.pow(dist, 2) +\n                                      1/2*(1-label) * torch.pow(torch.clamp(self.margin - dist, min=0.0), 2))\n\n\n        return loss\n    \nclass TripletLoss(torch.nn.Module):\n    \"\"\"\n    Triplet loss function.\n    \"\"\"\n\n    def __init__(self, margin=2.0):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, anchor, positive, negative):\n\n        squarred_distance_1 = (anchor - positive).pow(2).sum(1)\n        \n        squarred_distance_2 = (anchor - negative).pow(2).sum(1)\n        \n        triplet_loss = F.relu( self.margin + squarred_distance_1 - squarred_distance_2 ).mean()\n        \n        return triplet_loss","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.993533Z","iopub.status.idle":"2021-05-29T23:25:26.994118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cfg.train:    \n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    criterion = nn.BCEWithLogitsLoss()\n    for fold in range(cfg.folds):\n        run(fold)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.995225Z","iopub.status.idle":"2021-05-29T23:25:26.995769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not cfg.train and not cfg.analyze:\n    \n    WGTS = cfg.WGTS\n    PREDS = np.zeros(shape=(len(df_train), cfg.num_classes))\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    \n    def test_epoch(model, loader):\n\n        model.eval()\n        PREDS = []\n        TARGETS = []\n        \n        with torch.no_grad():\n            for data, labels in tqdm(loader):\n                data = data.to(device)\n                logits = model(data)\n                act = nn.Softmax(dim=1)\n                PREDS.append(act(logits.cpu()).numpy())\n                TARGETS.append(labels.cpu().numpy())\n                \n        return np.concatenate(np.array(PREDS)), np.concatenate(np.array(TARGETS))\n    \n    for fold in range(cfg.folds):  \n    \n        _,transforms_test = get_transforms(cfg.dim[fold])\n\n        test_dataset = SIIMDataset(df_train, subset='valid', transforms=transforms_test)\n\n        test_loader = DataLoader(test_dataset, \n                                   batch_size=cfg.batch_size[fold], \n                                   shuffle=False, \n                                   num_workers=2)\n\n        model = Model(backbone=cfg.backbone[fold], num_classes=cfg.num_classes, pretrained=False)\n\n        if cfg.pre_trained_weights[fold] is not None:\n            print(\"Loading Pretrained Weights.........\")\n            model.load_state_dict(torch.load(cfg.pre_trained_weights[fold]))\n            \n        model = model.to(device)\n        preds,TARGETS = test_epoch(model, test_loader)\n        PREDS += preds * WGTS[fold]\n        \n    df_preds = pd.DataFrame(columns = [\"image_id\", \"Target\", \"Prediction\", \"Pred_Probability\"])\n    df_preds[\"image_id\"] = df_train[\"image_id\"]\n    df_preds[\"Target\"] = np.argmax(TARGETS, axis = 1)\n    df_preds[\"Prediction\"] = np.argmax(PREDS, axis = 1)\n    df_preds[\"Pred_Probability\"] = np.max(PREDS, axis = 1)\n    df_preds.to_csv(\"Prediction_DataFrame.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.996954Z","iopub.status.idle":"2021-05-29T23:25:26.997657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if cfg.analyze:\n    \n    df = pd.read_csv(\"../input/siimpytorchmodels/Prediction_DataFrame.csv\")\n    if cfg.mode == \"binary\":\n        df[\"Org_Target\"]=np.argmax(np.array(df_train[cls]), axis=1)\n        \n    def image_analysis(target, predicted):\n    \n        id_inc = df_inc[df_inc[\"Target\"] == target][\"image_id\"] \n        paths = [df_train[df_train[\"image_id\"].isin(id_inc)][\"image_path\"].values, \n                 df_train[df_train[cls[predicted]] == 1][\"image_path\"].values]\n\n        rcParams['figure.figsize'] = 15,5\n        titles = [f\"Target label\\n{cls[target]}\", f\"Predicted label\\n{cls[predicted]}\"]\n        for i in range(2):\n            f, axarr = plt.subplots(1,5)\n            for p in range(5):\n                idx = i*5 + p\n                img = cv2.imread(paths[i][idx])\n                axarr[p].title.set_text(titles[i])\n                axarr[p].imshow(img)\n                plt.tight_layout(w_pad=1)\n    \n    def class_ratio(df, lbl=\"Target\", mode=\"all\"):\n        cl = [0,1,2,3]\n        for c in cl:\n            s = len(df[df[lbl]==c])\n            l = np.sum(df_train[cls[c]])\n            if mode == \"all\":\n                print(f\"Class {cls[c]}: {s/l*100}\")\n                print(f\"incorrect : {s} | Total : {l}\\n\")\n            else:\n                print(f\"Class {cls[c]}: {s/len(df)*100}\")\n\n    df_inc = df[df[\"Target\"] != df[\"Prediction\"]]\n    df_crr = df[df[\"Target\"] == df[\"Prediction\"]]\n    class_ratio(df_inc, \"Target\")\n    print(\"For label 0\")\n    class_ratio(df_inc[df_inc[\"Target\"] == 0], \"Prediction\", \"spec\")\n    print(\"\\nFor label 1\")\n    class_ratio(df_inc[df_inc[\"Target\"] == 1], \"Prediction\", \"spec\")\n    image_analysis(0,2)\n#     image_analysis(3,0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:26.998884Z","iopub.status.idle":"2021-05-29T23:25:26.999444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# M = Model(backbone=cfg.backbone[0], num_classes=cfg.num_classes)\n# model = SiameseModel(model=M, weights=cfg.pre_trained_weights[0], pretrained=False)\n# x = torch.stack([ds[i][0] for i in range(2)])\n# y = model(x)\n# y.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-29T23:25:27.000508Z","iopub.status.idle":"2021-05-29T23:25:27.001079Z"},"trusted":true},"execution_count":null,"outputs":[]}]}